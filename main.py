import os
import base64
import datetime
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from ultralytics import YOLO
import cv2
import tempfile
from PIL import Image
import numpy as np
import av
import torch
import tempfile
import time
import subprocess

torch.classes.__path__ = [os.path.join(torch.__path__[0], "classes")]
os.environ["STREAMLIT_WATCH_FILE"] = "false"

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO("./runs/train/rps_yolov115/weights/best.pt")  # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©
# model = YOLO(r"C:\workspace\7_ë”¥ëŸ¬ë‹\PJ_drone_save_human\runs\train\rps_yolov115\weights\best.pt")  # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë“œë¡ ìœ¼ë¡œ ìƒëª…ì„ ì‚´ë¦¬ëŠ” ê°ì§€ ì‹œìŠ¤í…œ",  layout="wide") #page_icon="data/Brone.png",

# ë°°ê²½ ì„¤ì • í•¨ìˆ˜
def set_background(image_path):
    with open(image_path, "rb") as f:
        data = f.read()
        encoded = base64.b64encode(data).decode()

    css = f"""
    <style>
    .stApp {{
        background-image: url("data:image/jpg;base64,{encoded}");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

# ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì •
# set_background("data/drone.png")

# ì‚¬ì´ë“œë°” ë©”ë‰´
with st.sidebar:
    st.sidebar.image("./image/MeaMi.png")
    # st.sidebar.image(r"C:\workspace\7_ë”¥ëŸ¬ë‹\PJ_drone_save_human\image\MeaMi.png")
    # st.image("data/logo.png", width=120)
    st.title("ë¶„ì„ ëª¨ë¸ ì„ íƒ")
    page = st.selectbox("ì´ë™í•  ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["í™ˆ", "ì†Œê°œ", "ì‹¤ì‹œê°„ ì˜ìƒ","ì´ë¯¸ì§€ ë¶„ì„", "ì˜ìƒ ë¶„ì„", "ë¬¸ì˜í•˜ê¸°"], key="sidebar_select")
    st.sidebar.markdown(""" 
        8ì¡°
        - ì†ì˜ì„
        - ì´ì¢…í˜„
        - ë°°ì„±ìš°
        - ë°•ë²”ê¸°

        ---
        - ì‚¬ìš©ëª¨ë¸: YOLOv11 (.pt)
        - ë°ì´í„° ìˆ˜ì§‘ì²˜: roboflow
        - ì›¹ ì œì‘: streamlit
    """)

# ìƒˆë¡œê³ ì¹¨ ì‹œ í™ˆìœ¼ë¡œ
if 'page' not in st.session_state:
    st.session_state.page = "í™ˆ"

if page != st.session_state.page:
    st.session_state.page = page
    st.rerun()

# ë©”ì¸ í˜ì´ì§€ ì œëª©
st.markdown(f"<h2 style='text-align:center;'>ë“œë¡  ê°ì§€ ì‹œìŠ¤í…œ</h2>", unsafe_allow_html=True)
st.markdown(f"<div style='font-size:18px; font-weight:bold;'>ğŸ“Œ í˜„ì¬ í˜ì´ì§€: {page}</div>", unsafe_allow_html=True)

# ê³µí†µ YOLO íƒì§€ í•¨ìˆ˜
def detect_and_draw(image):
    results = model(image)
    result = results[0]
    boxes = result.boxes
    class_ids = boxes.cls.tolist()
    confidences = boxes.conf.tolist()
    xyxy = boxes.xyxy.tolist()

    for i, box in enumerate(xyxy):
        if int(class_ids[i]) == 0:  # 0ë²ˆ í´ë˜ìŠ¤: ì‚¬ëŒ
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, f'person {confidences[i]:.2f}', (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return image

# ì¶”ê°€//ì‹¤ì‹œê°„ íƒì§€
frame_count = 0
def process_frame(frame):
    global frame_count
    img = frame.to_ndarray(format="bgr24")
    if frame_count % 5 == 0:
        result = detect_and_draw(img)
        process_frame.last_result = result
    frame_count += 1
    return av.VideoFrame.from_ndarray(process_frame.last_result, format="bgr24")
process_frame.last_result = None

# ë™ì˜ìƒ ì½”ë± ë¬¸ì œ ì²˜ë¦¬ í•¨ìˆ˜
def convert_to_h264(input_path, output_path):
    command = [
        "ffmpeg", "-y", "-i", input_path,
        "-vcodec", "libx264", "-acodec", "aac", output_path
    ]
    subprocess.run(command, check=True)

# ì‚¬ì§„ ê°¤ëŸ¬ë¦¬ ì²˜ë¦¬
if page == "ì´ë¯¸ì§€ ë¶„ì„":
    st.title("ğŸ“· ì´ë¯¸ì§€ ë¶„ì„")
    uploaded_image = st.file_uploader("ğŸ“¤ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

    if uploaded_image is not None:
        image = Image.open(uploaded_image).convert("RGB")
        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        processed_img = detect_and_draw(open_cv_image)
        st.image(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB), use_container_width=True)

# ë™ì˜ìƒ ê°¤ëŸ¬ë¦¬ ì²˜ë¦¬
elif page == "ì˜ìƒ ë¶„ì„":
    st.title("ğŸï¸ ì˜ìƒ ë¶„ì„")
    uploaded_video = st.file_uploader("ğŸ“¤ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])

    # if uploaded_video is not None:
    #     tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    #     tfile.write(uploaded_video.read())

    #     # ë™ì˜ìƒ ìº¡ì²˜
    #     cap = cv2.VideoCapture(tfile.name)
    #     stframe = st.empty()  # ì‹¤ì‹œê°„ í”„ë ˆì„ í‘œì‹œìš© placeholder

    #     frame_interval = 1 # í”„ë ˆì„ ê°„ê²© ì¤„ì´ê¸° (ë” ë¹ ë¥´ê²Œ ë³´ì—¬ì¤Œ)
    #     frame_count = 0

    #     while cap.isOpened():
    #         ret, frame = cap.read()
    #         # frame = cv2.resize(frame,(640,480))
    #         if not ret:
    #             break

    #         if frame_count % frame_interval == 0:
    #             processed = detect_and_draw(frame)
    #             stframe.image(cv2.cvtColor(processed, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)

    #         frame_count += 1

    #     cap.release()
    
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_video.read())
        tfile.close()

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        out_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(out_file.name, fourcc, fps, (width, height))

        progress_bar = st.progress(0, text="íƒì§€ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")

        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            if frame.shape[1] != width or frame.shape[0] != height:
                frame = cv2.resize(frame, (width, height))

            processed = detect_and_draw(frame)
            out.write(processed)

            percent_complete = int((frame_idx + 1) / total_frames * 100)
            progress_bar.progress(percent_complete, text=f"ë™ì˜ìƒ ì²˜ë¦¬ ì¤‘... ({percent_complete}%)")
            frame_idx += 1

            time.sleep(0.001)

        cap.release()
        out.release()
        progress_bar.empty()

        # ë³€í™˜ íŒŒì¼ë„ ì„ì‹œ íŒŒì¼ë¡œ ìƒì„±
        converted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        convert_to_h264(out_file.name, converted_file.name)

        st.success("íƒì§€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ì—ì„œ ê²°ê³¼ ì˜ìƒì„ í™•ì¸í•˜ì„¸ìš”.")

        # ë³€í™˜ëœ íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ ë„˜ê¹€
        with open(converted_file.name, "rb") as video_file:
            st.video(video_file.read())
            

elif page == "ì‹¤ì‹œê°„ ì˜ìƒ":
    st.title("ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì—°ë™")
    st.write("ì›¹ìº ê³¼ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")

    # cap = cv2.VideoCapture(0)  # 0ë²ˆ ì¹´ë©”ë¼ (ê¸°ë³¸ ë‚´ì¥ ìº )
    # cap.set(cv2.CAP_PROP_FRAME_WIDTH,4080)
    # cap.set(cv2.CAP_PROP_FRAME_HEIGHT,2040)
    # stframe = st.empty()

    # while True:
    #     ret,frame = cap.read()
    #     if not ret:
    #         st.warning("ì¹´ë©”ë¼ê°€ ì—†ìª™")
    #         break
    #     frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
    #     frame = cv2.resize(frame, (0, 0), fx=0.3, fy=0.3, interpolation=cv2.INTER_AREA)
       
    #     # stframe.image(frame,channels="RGB")
    #     processed_frame = detect_and_draw(frame)

    #     stframe.image(processed_frame, channels="RGB",width=1000)

    #     # ì‚´ì§ sleepì„ ì¤˜ì„œ ë„ˆë¬´ ê³¼ë¶€í•˜ ë°©ì§€
    #     time.sleep(0.02)

    #     if cv2.waitKey(1) == ord("q"):
    #         break
    # cap.release()
    
    webrtc_streamer(
        key="realtime",
        video_frame_callback=process_frame,
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
        rtc_configuration={
            "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
        }
    )

# ê¸°íƒ€ í˜ì´ì§€
elif page == "í™ˆ":
    st.markdown(
        """
        <h2 style='text-align: center;'>ğŸš€ ë“œë¡ ì„ í™œìš©í•œ ì‹¤ì¢…ì ìˆ˜ìƒ‰ ì‹œìŠ¤í…œ</h2>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p style='text-align: center; font-size:18px;'>
        ì´ ì‹œìŠ¤í…œì€ ë“œë¡ ì´ ì´¬ì˜í•œ ì˜ìƒì—ì„œ ì‚¬ëŒìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ë¬¼ì²´ë¥¼ í¬ì°©í•©ë‹ˆë‹¤.
        </p>
        """,
        unsafe_allow_html=True
    )

    # ì´ë¯¸ì§€ ì¤‘ì•™ ì •ë ¬
    with open("./image/ë”¥ëŸ¬ë‹í”„ë¡œì íŠ¸.png", "rb") as img_file:
    # with open(r"C:\workspace\7_ë”¥ëŸ¬ë‹\PJ_drone_save_human\image\ë”¥ëŸ¬ë‹í”„ë¡œì íŠ¸.png", "rb") as img_file:
        img_bytes = img_file.read()
        encoded = base64.b64encode(img_bytes).decode()

    st.markdown(
        f"""
        <div style="text-align: center;">
            <img src="data:image/png;base64,{encoded}" width="660">
        </div>
        """,
        unsafe_allow_html=True
    )
