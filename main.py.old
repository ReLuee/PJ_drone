import os
import base64
import datetime
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from ultralytics import YOLO
import cv2
import tempfile
from PIL import Image
import numpy as np
import av
import torch
import tempfile
import time
import subprocess
import math

torch.classes.__path__ = [os.path.join(torch.__path__[0], "classes")]
os.environ["STREAMLIT_WATCH_FILE"] = "false"

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO("./runs/train/rps_yolov115/weights/best.pt")  # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë“œë¡ ìœ¼ë¡œ ìƒëª…ì„ ì‚´ë¦¬ëŠ” ê°ì§€ ì‹œìŠ¤í…œ",  layout="wide") #page_icon="data/Brone.png",

# ë°°ê²½ ì„¤ì • í•¨ìˆ˜
def set_background(image_path):
    with open(image_path, "rb") as f:
        data = f.read()
        encoded = base64.b64encode(data).decode()

    css = f"""
    <style>
    .stApp {{
        background-image: url("data:image/jpg;base64,{encoded}");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

# ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì •
# set_background("data/drone.png")

# ì‚¬ì´ë“œë°” ë©”ë‰´
with st.sidebar:
    st.sidebar.image("./image/MeaMi.png")
    # st.image("data/logo.png", width=120)
    st.title("ë¶„ì„ ëª¨ë¸ ì„ íƒ")
    page = st.selectbox("ì´ë™í•  ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["í™ˆ", "ì†Œê°œ", "ì‹¤ì‹œê°„ ì˜ìƒ","ì´ë¯¸ì§€ ë¶„ì„", "ì˜ìƒ ë¶„ì„", "ì˜ìƒ ì¦‰ì‹œ ë¶„ì„", "ë¬¸ì˜í•˜ê¸°"], key="sidebar_select")
    st.sidebar.markdown(""" 
        8ì¡°
        - ì†ì˜ì„
        - ì´ì¢…í˜„
        - ë°°ì„±ìš°
        - ë°•ë²”ê¸°

        ---
        - ì‚¬ìš©ëª¨ë¸: YOLOv11n
        - ë°ì´í„° ìˆ˜ì§‘ì²˜: roboflow
        - ì›¹ ì œì‘: streamlit
    """)

# ìƒˆë¡œê³ ì¹¨ ì‹œ í™ˆìœ¼ë¡œ
if 'page' not in st.session_state:
    st.session_state.page = "í™ˆ"

if page != st.session_state.page:
    st.session_state.page = page
    st.rerun()

# ë©”ì¸ í˜ì´ì§€ ì œëª©
st.markdown(f"<h2 style='text-align:center;'>ë“œë¡  ê°ì§€ ì‹œìŠ¤í…œ</h2>", unsafe_allow_html=True)
st.markdown(f"<div style='font-size:18px; font-weight:bold;'>ğŸ“Œ í˜„ì¬ í˜ì´ì§€: {page}</div>", unsafe_allow_html=True)

# # ê³µí†µ YOLO íƒì§€ í•¨ìˆ˜
# def detect_and_draw(image):
#     results = model(image)
#     result = results[0]
#     boxes = result.boxes
#     class_ids = boxes.cls.tolist()
#     confidences = boxes.conf.tolist()
#     xyxy = boxes.xyxy.tolist()

#     for i, box in enumerate(xyxy):
#         if int(class_ids[i]) == 0:  # 0ë²ˆ í´ë˜ìŠ¤: ì‚¬ëŒ
#             x1, y1, x2, y2 = map(int, box)
#             cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
#             cv2.putText(image, f'person {confidences[i]:.2f}', (x1, y1 - 10),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
#     return image

# ê³µí†µ YOLO íƒì§€ í•¨ìˆ˜ (ë°•ìŠ¤ ì •ë³´ ë°˜í™˜)
def detect_and_draw(image):
    results = model(image)
    result = results[0]
    boxes = result.boxes
    class_ids = boxes.cls.tolist()
    confidences = boxes.conf.tolist()
    xyxy = boxes.xyxy.tolist()

    detections = []
    for i, box in enumerate(xyxy):
        if int(class_ids[i]) == 0:  # 0ë²ˆ í´ë˜ìŠ¤: ì‚¬ëŒ
            x1, y1, x2, y2 = map(int, box)
            conf = confidences[i]
            detections.append((x1, y1, x2, y2, conf))
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, f'person {conf:.2f}', (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return image, detections

# ë°•ìŠ¤ ê·¸ë¦¬ê¸°ë§Œ í•˜ëŠ” í•¨ìˆ˜
def draw_boxes(image, detections):
    for x1, y1, x2, y2, conf in detections:
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, f'person {conf:.2f}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return image


# ì¶”ê°€//ì‹¤ì‹œê°„ íƒì§€
frame_count = 0
def process_frame(frame):
    global frame_count
    img = frame.to_ndarray(format="bgr24")
    # if frame_count % 5 == 0:
    result = detect_and_draw(img)[0]
    process_frame.last_result = result
    frame_count += 1
    return av.VideoFrame.from_ndarray(process_frame.last_result, format="bgr24")
process_frame.last_result = None

# ë™ì˜ìƒ ì½”ë± ë¬¸ì œ ì²˜ë¦¬ í•¨ìˆ˜
def convert_to_h264(input_path, output_path):
    command = [
        "ffmpeg", "-y", "-i", input_path,
        "-vcodec", "libx264", "-acodec", "aac", output_path
    ]
    subprocess.run(command, check=True)

# ì‚¬ì§„ ê°¤ëŸ¬ë¦¬ ì²˜ë¦¬
if page == "ì´ë¯¸ì§€ ë¶„ì„":
    st.title("ğŸ“· ì´ë¯¸ì§€ ë¶„ì„")
    uploaded_image = st.file_uploader("ğŸ“¤ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

    if uploaded_image is not None:
        image = Image.open(uploaded_image).convert("RGB")
        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        processed_img = detect_and_draw(open_cv_image)[0]
        st.image(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB), use_container_width=True)

# # ë™ì˜ìƒ ê°¤ëŸ¬ë¦¬ ì²˜ë¦¬
# elif page == "ì˜ìƒ ë¶„ì„":
#     st.title("ğŸï¸ ì˜ìƒ ë¶„ì„")
#     uploaded_video = st.file_uploader("ğŸ“¤ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])
    
#     if uploaded_video is not None:
#         tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#         tfile.write(uploaded_video.read())
#         tfile.close()

#         cap = cv2.VideoCapture(tfile.name)
#         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#         fps = cap.get(cv2.CAP_PROP_FPS)
#         width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

#         out_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#         out = cv2.VideoWriter(out_file.name, fourcc, fps, (width, height))

#         progress_bar = st.progress(0, text="íƒì§€ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")

#         frame_interval = 3 
#         frame_idx = 0
#         while cap.isOpened():
#             ret, frame = cap.read()
#             if not ret:
#                 break

#             if frame.shape[1] != width or frame.shape[0] != height:
#                 frame = cv2.resize(frame, (width, height))
            
#             if frame_idx % frame_interval == 0:
#                 processed = detect_and_draw(frame)
#             else:
#                 processed = frame
#             out.write(processed)

#             percent_complete = int((frame_idx + 1) / total_frames * 100)
#             progress_bar.progress(percent_complete, text=f"ë™ì˜ìƒ ì²˜ë¦¬ ì¤‘... ({percent_complete}%)")
#             frame_idx += 1

#             time.sleep(0.001)

#         cap.release()
#         out.release()
#         progress_bar.empty()

#         # ë³€í™˜ íŒŒì¼ë„ ì„ì‹œ íŒŒì¼ë¡œ ìƒì„±
#         converted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#         convert_to_h264(out_file.name, converted_file.name)

#         st.success("íƒì§€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ì—ì„œ ê²°ê³¼ ì˜ìƒì„ í™•ì¸í•˜ì„¸ìš”.")

#         # ë³€í™˜ëœ íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ ë„˜ê¹€
#         with open(converted_file.name, "rb") as video_file:
#             st.video(video_file.read())

# ë™ì˜ìƒ ê°¤ëŸ¬ë¦¬ ì²˜ë¦¬
elif page == "ì˜ìƒ ë¶„ì„":
    st.title("ğŸï¸ ì˜ìƒ ë¶„ì„")
    uploaded_video = st.file_uploader("ğŸ“¤ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])
    
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_video.read())
        tfile.close()

        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        out_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(out_file.name, fourcc, fps, (width, height))

        progress_bar = st.progress(0, text="íƒì§€ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")

        frame_interval = round(fps*0.1)
        frame_idx = 0
        last_detections = []  # ë§ˆì§€ë§‰ íƒì§€ ê²°ê³¼ ì €ì¥

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            if frame.shape[1] != width or frame.shape[0] != height:
                frame = cv2.resize(frame, (width, height))
            
            if frame_idx % frame_interval == 0:
                processed, detections = detect_and_draw(frame)
                last_detections = detections  # ìµœì‹  íƒì§€ ê²°ê³¼ ì €ì¥
            else:
                # ì´ì „ íƒì§€ ê²°ê³¼ë¡œ ë°•ìŠ¤ë§Œ ê·¸ë¦¼
                processed = draw_boxes(frame.copy(), last_detections)
            out.write(processed)

            percent_complete = int((frame_idx + 1) / total_frames * 100)
            progress_bar.progress(percent_complete, text=f"ë™ì˜ìƒ ì²˜ë¦¬ ì¤‘... ({percent_complete}%)")
            frame_idx += 1

            # time.sleep(0.001)  # í•„ìš”ì‹œë§Œ ì‚¬ìš©

        cap.release()
        out.release()
        progress_bar.empty()

        # ë³€í™˜ íŒŒì¼ë„ ì„ì‹œ íŒŒì¼ë¡œ ìƒì„±
        converted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        with st.spinner("ì¸ì½”ë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
            convert_to_h264(out_file.name, converted_file.name)

        st.success("íƒì§€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ì—ì„œ ê²°ê³¼ ì˜ìƒì„ í™•ì¸í•˜ì„¸ìš”.")

        # ë³€í™˜ëœ íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ ë„˜ê¹€
        with open(converted_file.name, "rb") as video_file:
            st.video(video_file.read())            


# ë™ì˜ìƒ ì‹¤ì‹œê°„ ë¶„ì„ í›„ ë°˜í™˜
elif page == "ì˜ìƒ ì¦‰ì‹œ ë¶„ì„":
    st.title("ğŸï¸ ì˜ìƒ ì¦‰ì‹œ ë¶„ì„(ë‚®ì€ FPS)")
    uploaded_video = st.file_uploader("ğŸ“¤ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi", "mkv"])

    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())
        tfile.close()

        # ë™ì˜ìƒ ìº¡ì²˜
        cap = cv2.VideoCapture(tfile.name)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        stframe = st.empty()  # ì‹¤ì‹œê°„ í”„ë ˆì„ í‘œì‹œìš© placeholder

        start_time = time.time()
        
        frame_interval = math.round(fps*0.4) # ì¶œë ¥ í”„ë ˆì„ ê°„ê²©
        frame_idx = 0
        last_detections = []  # ë§ˆì§€ë§‰ íƒì§€ ê²°ê³¼ ì €ì¥

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame.shape[1] != width or frame.shape[0] != height:
                frame = cv2.resize(frame, (width, height))

            if frame_idx % frame_interval == 0:
                processed, detections = detect_and_draw(frame)
                last_detections = detections

                stframe.image(cv2.cvtColor(processed, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
            
            # fpsì— ë§ì¶˜ ì‹œê°„ ì¡°ì ˆ
            elapsed_time = time.time() - start_time
            expected_time = frame_idx / fps
            if elapsed_time < expected_time:
                time.sleep(expected_time - elapsed_time)

            frame_idx += 1

        cap.release()


elif page == "ì‹¤ì‹œê°„ ì˜ìƒ":
    st.title("ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì—°ë™")
    st.write("ì›¹ìº ê³¼ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")

    # cap = cv2.VideoCapture(0)  # 0ë²ˆ ì¹´ë©”ë¼ (ê¸°ë³¸ ë‚´ì¥ ìº )
    # cap.set(cv2.CAP_PROP_FRAME_WIDTH,4080)
    # cap.set(cv2.CAP_PROP_FRAME_HEIGHT,2040)
    # stframe = st.empty()

    # while True:
    #     ret,frame = cap.read()
    #     if not ret:
    #         st.warning("ì¹´ë©”ë¼ê°€ ì—†ìª™")
    #         break
    #     frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
    #     frame = cv2.resize(frame, (0, 0), fx=0.3, fy=0.3, interpolation=cv2.INTER_AREA)
       
    #     # stframe.image(frame,channels="RGB")
    #     processed_frame = detect_and_draw(frame)

    #     stframe.image(processed_frame, channels="RGB",width=1000)

    #     # ì‚´ì§ sleepì„ ì¤˜ì„œ ë„ˆë¬´ ê³¼ë¶€í•˜ ë°©ì§€
    #     time.sleep(0.02)

    #     if cv2.waitKey(1) == ord("q"):
    #         break
    # cap.release()
    
    webrtc_streamer(
        key="realtime",
        video_frame_callback=process_frame,
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={
            "video": True,
            "audio": False
        },
        async_processing=True,
        rtc_configuration={
            "iceServers": [{"urls": "stun:stun.l.google.com:19302"},
                        {"urls": "stun:stun1.l.google.com:19302"},
                        {"urls": "stun:stun2.l.google.com:19302"},
                        {"urls": "stun:stun3.l.google.com:19302"},
                        {"urls": "stun:stun4.l.google.com:19302"},]
        }
    )

# ê¸°íƒ€ í˜ì´ì§€
elif page == "í™ˆ":
    st.markdown(
        """
        <h2 style='text-align: center;'>ğŸš€ ë“œë¡ ì„ í™œìš©í•œ ì‹¤ì¢…ì ìˆ˜ìƒ‰ ì‹œìŠ¤í…œ</h2>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <p style='text-align: center; font-size:18px;'>
        ì´ ì‹œìŠ¤í…œì€ ë“œë¡ ì´ ì´¬ì˜í•œ ì˜ìƒì—ì„œ ì‚¬ëŒìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ë¬¼ì²´ë¥¼ í¬ì°©í•©ë‹ˆë‹¤.
        </p>
        """,
        unsafe_allow_html=True
    )

    # ì´ë¯¸ì§€ ì¤‘ì•™ ì •ë ¬
    with open("./image/ë”¥ëŸ¬ë‹í”„ë¡œì íŠ¸.png", "rb") as img_file:
        img_bytes = img_file.read()
        encoded = base64.b64encode(img_bytes).decode()

    st.markdown(
        f"""
        <div style="text-align: center;">
            <img src="data:image/png;base64,{encoded}" width="660">
        </div>
        """,
        unsafe_allow_html=True
    )
